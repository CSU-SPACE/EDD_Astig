# EED-Astig: A Multimodal Dataset of Pediatric External Eye Images and Behavioral Parameters for Astigmatism Severity Prediction

## 1. Project Overview

This project aims to automate the prediction of astigmatism through computer vision and machine learning techniques. It leverages deep learning models to extract high-precision biological features from eye images, including keypoint detection and cornea segmentation. Based on these features, a series of quantitative metrics are calculated. Finally, classic machine learning classification models are used to predict astigmatism based on these metrics.

The entire pipeline constitutes an end-to-end solution from image to diagnostic prediction, offering new possibilities for computer-aided diagnosis of ophthalmic diseases.

## 2. Data and Model Preparation

The dataset and pre-trained model weights are too large to be hosted on GitHub directly. Please follow the steps below to download them separately and set up the project.

1.  **Download the Dataset (from Zenodo)**:
    * **Click this permanent link to download the dataset from Zenodo: [https://doi.org/10.5281/zenodo.17231120](https://doi.org/10.5281/zenodo.17231120)**
    * On the Zenodo page, download the `EED-Astig.zip` file.
    * Unzip it and ensure the resulting `EED-Astig` folder is placed in the root directory of this project.

2.  **Download the Model Weights (from Google Drive)**:
    * **Click this link to download the model weights from Google Drive: [Google Drive Link](https://drive.google.com/drive/folders/1nmKPj-Ya9ovyu2MgFmfiW23rO9auplHF?usp=drive_link)**
    * From the Google Drive page, download the `pth.zip` file.
    * Unzip it and ensure the resulting `pth` folder is placed in the root directory of this project.

3.  **Verify the Directory Structure**:
    After completing these steps, your project's root directory should look like this:
    ```
    .
    ├── EED-Astig/          <-- Unzipped from Zenodo
    ├── classification/
    ├── mmpose/
    ├── mmsegmentation/
    ├── pth/                <-- Unzipped from Google Drive
    └── README.md
    ...
    ```

**Important**: Please ensure you have a `.gitignore` file in your project's root directory to prevent accidentally uploading these large folders to GitHub.

## 3. License and Data Use Agreement

This project is released under a dual-license structure: the code is open-sourced under the MIT License, while the dataset is governed by a separate Data Use Agreement (DUA).

* **Code License**: All source code in this repository is licensed under the **[MIT License](LICENSE)**. You are free to use, modify, and distribute the code, provided that you include the original copyright notice in your copies.

* **Data Use Agreement**: Access to and use of the EED-Astig dataset is subject to the terms outlined in the **[EED-Astig Data Use Agreement (DUA) 1.0.0.pdf](EED-Astig%20Data%20Use%20Agreement%20(DUA)%201.0.0.pdf)**. By downloading or using the dataset, you agree to be bound by its terms. Key restrictions include:
    * **Non-Commercial Use Only**: The dataset may only be used for non-commercial research and analysis purposes.
    * **No Redistribution**: You may not redistribute, share, or transfer the dataset or any portion of it to any third party.
    * **No Re-identification**: You must not attempt to re-identify any individual participant whose data is contained in the dataset.
    * **Data Security**: You must implement appropriate technical measures to ensure the security of the data.

Please read the full DUA document carefully before using the dataset.


## 4. Directory Structure

```
.
├── EED-Astig/                    # Dataset root directory (downloaded separately)
│   ├── Annotations/              # Contains JSON annotation files for all images
│   ├── Images/                   # Contains all original eye images
│   └── Parameter.xls             # Original data table with sample IDs, ground truth parameters, etc.
│
├── classification/               # Code related to the classification task
│   ├── model_comparison_results/ # (Optional) Stores performance comparison results of different models
│   ├── classification.py         # Main classification script for training and testing prediction models
│   ├── data_new.csv              # Feature data generated by process_anno.py for model training
│   └── process_anno.py           # Core script: reads Annotations, calculates all metrics, and generates data_new.csv
│
├── mmpose/                       # Keypoint detection model configs
│   └── EEDAstig/
│       ├── eye.py                # Config file for the eye keypoint detection model
│       └── eyelash.py            # Config file for the eyelash keypoint detection model
│
├── mmsegmentation/               # Image segmentation model configs
│   └── EEDAstig/
│       └── deeplabv3plus_r50-d8_...py # Config file for the cornea segmentation model (DeepLabV3+)
│
└── pth/                          # Contains all pre-trained model weights (downloaded separately)
    ├── cornea.pth                # Cornea segmentation model weights
    ├── eye.pth                   # Eye keypoint detection model weights
    └── eyelash.pth               # Eyelash keypoint detection model weights
```

## 5. Usage

### Step 1: Environment Setup

Ensure all required libraries for this project are installed. It is recommended to create a separate Python virtual environment.
```bash
# Install dependencies from the requirements file
pip install -r requirements.txt
```
*Note: For complex deep learning libraries like PyTorch, MMPose, and MMSegmentation, it is strongly recommended to follow their official installation guides to ensure compatibility with your system's CUDA version.*

### Step 2: Data and Annotation Preparation

1.  Follow the instructions in the **"Data and Model Preparation"** section above to download and place the dataset and model weights.
2.  (If generating new annotations) Use the `MMPose` and `MMSegmentation` frameworks with the provided configs and downloaded weights to run inference on your own images. Store the resulting JSON annotation files in the `EED-Astig/Annotations/` directory.

### Step 3: Calculate Quantitative Features

Run the `process_anno.py` script to process all annotation files into a structured feature dataset. Open your terminal and execute the following command:
```bash
python classification/process_anno.py \
    -t "EED-Astig/Parameter.xls" \
    -i "EED-Astig/Annotations/" \
    -o "classification/data_new.csv"
```
* `-t`: Path to your original data table.
* `-i`: Path to the folder containing all JSON annotations.
* `-o`: Specifies the output filename for the feature data.

After successful execution, you will find the `data_new.csv` file in the `classification/` directory.

### Step 4: Train the Classification Model

Finally, run the `classification.py` script to train the astigmatism prediction model and evaluate its performance.
```bash
python classification/classification.py
```
*(Please ensure the file path in the `classification.py` script is set to read `"data_new.csv"`)*

The script will output performance metrics such as accuracy, recall, and F1-score.

## 6. Model Weights

The following pre-trained model weights are provided in the `pth/` directory (downloaded from the link above):

* `pth/cornea.pth`: For segmenting the cornea region.
* `pth/eye.pth`: For detecting keypoints such as canthi and the lower eyelid.
* `pth/eyelash.pth`: For detecting the start and end points of eyelashes.

These weights are core assets of this project.

## 7. Acknowledgements

The completion of this project would not have been possible without the support of the incredible open-source community and its powerful tools. We would like to extend our special thanks to the following projects for their significant contributions:

* **[MMPose](https://github.com/open-mmlab/mmpose)**: For providing a high-performance and accurate framework for eye and eyelash keypoint detection.
* **[MMSegmentation](https://github.com/open-mmlab/mmsegmentation)**: An excellent semantic segmentation toolbox that was crucial for the cornea segmentation task in this project.
* **[Scikit-learn](https://github.com/scikit-learn/scikit-learn)**: For offering a rich and robust library of machine learning models and tools, which formed the foundation for our final astigmatism classification.

Our sincere gratitude goes to the developers and contributors of these open-source projects for their invaluable work that accelerates the pace of scientific research and innovation.

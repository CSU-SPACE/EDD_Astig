# EED-Astig: A Multimodal Dataset of Pediatric External Eye Images and Behavioral Parameters for Astigmatism Severity Prediction

## 1. Project Overview

This project aims to automate the prediction of astigmatism through computer vision and machine learning techniques. It leverages deep learning models to extract high-precision biological features from eye images, including keypoint detection and cornea segmentation. Based on these features, a series of quantitative metrics are calculated. Finally, classic machine learning classification models are used to predict astigmatism based on these metrics.

The entire pipeline constitutes an end-to-end solution from image to diagnostic prediction, offering new possibilities for computer-aided diagnosis of ophthalmic diseases.

## 2. Data and Model Preparation

The dataset and pre-trained model weights are too large to be hosted on GitHub directly. Please follow these steps to download and set them up:

1.  **Access the Download Link**:
    * **Click this link to access the Google Drive folder: [Download Dataset & Model Weights](https://drive.google.com/drive/folders/1nmKPj-Ya9ovyu2MgFmfiW23rO9auplHF?usp=drive_link)**

2.  **Download and Unzip the Files**:
    * From the Google Drive page, download both `EED-Astig.zip` and `pth.zip`.
    * Unzip `EED-Astig.zip` and ensure the resulting `EED-Astig` folder is placed in the root directory of this project.
    * Unzip `pth.zip` and ensure the resulting `pth` folder is placed in the root directory of this project.

3.  **Verify the Directory Structure**:
    After completing these steps, your project directory should look like this:

    ```
    .
    ├── EED-Astig/          <-- Unzipped from your download
    ├── classification/
    ├── mmpose/
    ├── mmsegmentation/
    ├── pth/                <-- Unzipped from your download
    └── README.md
    ...
    ```

**Important**: Make sure you have a `.gitignore` file in your project's root to prevent accidentally uploading these large directories to GitHub. It should contain at least the following lines:

```
# Ignore dataset and model weights
EED-Astig/
pth/

# Ignore compressed files
*.zip
```

## 3. Workflow

The project's workflow is divided into three core stages:

1.  **Deep Learning-Based Feature Extraction**:
    * **Keypoint Detection (MMPose)**: Utilizes the `MMPose` framework to train models for detecting **eye landmarks** (e.g., canthi, lower eyelid points) and **eyelash positions**.
    * **Cornea Segmentation (MMSegmentation)**: Employs the `MMSegmentation` framework with a `DeepLabV3+` model to perform pixel-level segmentation of the **cornea region**.

2.  **Quantitative Metric Calculation**:
    * A core processing script (`process_anno.py`) has been developed to read the JSON annotation files (containing keypoints and cornea polygons) generated by the deep learning models.
    * The script automatically calculates dozens of geometric and morphological metrics, such as inner/outer canthal distance, eyelash ptosis angle, precise cornea center location, and various relative distances and angles.

3.  **Classification and Prediction**:
    * The calculated quantitative metrics are merged with the original data table (`Parameter.xls`) to generate a comprehensive feature dataset (`data_new.csv`).
    * This dataset is then used to train and evaluate various classification models (e.g., XGBoost, RandomForest, SVM) to predict the degree of astigmatism.

## 4. Directory Structure

```
.
├── EED-Astig/                    # Dataset root directory (downloaded separately)
│   ├── Annotations/              # Contains JSON annotation files for all images
│   ├── Images/                   # Contains all original eye images
│   └── Parameter.xls             # Original data table with sample IDs, ground truth parameters, etc.
│
├── classification/               # Code related to the classification task
│   ├── model_comparison_results/ # (Optional) Stores performance comparison results of different models
│   ├── classification.py         # Main classification script for training and testing prediction models
│   ├── data_new.csv              # Feature data generated by process_anno.py for model training
│   └── process_anno.py           # Core script: reads Annotations, calculates all metrics, and generates data_new.csv
│
├── mmpose/                       # Keypoint detection model configs
│   └── EEDAstig/
│       ├── eye.py                # Config file for the eye keypoint detection model
│       └── eyelash.py            # Config file for the eyelash keypoint detection model
│
├── mmsegmentation/               # Image segmentation model configs
│   └── EEDAstig/
│       └── deeplabv3plus_r50-d8_...py # Config file for the cornea segmentation model (DeepLabV3+)
│
└── pth/                          # Contains all pre-trained model weights (downloaded separately)
    ├── cornea.pth                # Cornea segmentation model weights
    ├── eye.pth                   # Eye keypoint detection model weights
    └── eyelash.pth               # Eyelash keypoint detection model weights
```

## 5. Usage

### Step 1: Environment Setup

Ensure all required libraries for this project are installed. It is recommended to create a separate Python virtual environment.
```bash
# Install dependencies from the requirements file
pip install -r requirements.txt
```
*Note: For complex deep learning libraries like PyTorch, MMPose, and MMSegmentation, it is strongly recommended to follow their official installation guides to ensure compatibility with your system's CUDA version.*

### Step 2: Data and Annotation Preparation

1.  Follow the instructions in the **"Data and Model Preparation"** section above to download and place the dataset and model weights.
2.  (If generating new annotations) Use the `MMPose` and `MMSegmentation` frameworks with the provided configs and downloaded weights to run inference on your own images. Store the resulting JSON annotation files in the `EED-Astig/Annotations/` directory.

### Step 3: Calculate Quantitative Features

Run the `process_anno.py` script to process all annotation files into a structured feature dataset. Open your terminal and execute the following command:
```bash
python classification/process_anno.py \
    -t "EED-Astig/Parameter.xls" \
    -i "EED-Astig/Annotations/" \
    -o "classification/data_new.csv"
```
* `-t`: Path to your original data table.
* `-i`: Path to the folder containing all JSON annotations.
* `-o`: Specifies the output filename for the feature data.

After successful execution, you will find the `data_new.csv` file in the `classification/` directory.

### Step 4: Train the Classification Model

Finally, run the `classification.py` script to train the astigmatism prediction model and evaluate its performance.
```bash
python classification/classification.py
```
*(Please ensure the file path in the `classification.py` script is set to read `"data_new.csv"`)*

The script will output performance metrics such as accuracy, recall, and F1-score.

## 6. Model Weights

The following pre-trained model weights are provided in the `pth/` directory (downloaded from the link above):

* `pth/cornea.pth`: For segmenting the cornea region.
* `pth/eye.pth`: For detecting keypoints such as canthi and the lower eyelid.
* `pth/eyelash.pth`: For detecting the start and end points of eyelashes.

These weights are core assets of this project.

## 7. Acknowledgements

The completion of this project would not have been possible without the support of the incredible open-source community and its powerful tools. We would like to extend our special thanks to the following projects for their significant contributions:

* **[MMPose](https://github.com/open-mmlab/mmpose)**: For providing a high-performance and accurate framework for eye and eyelash keypoint detection.
* **[MMSegmentation](https://github.com/open-mmlab/mmsegmentation)**: An excellent semantic segmentation toolbox that was crucial for the cornea segmentation task in this project.
* **[Scikit-learn](https://github.com/scikit-learn/scikit-learn)**: For offering a rich and robust library of machine learning models and tools, which formed the foundation for our final astigmatism classification.

Our sincere gratitude goes to the developers and contributors of these open-source projects for their invaluable work that accelerates the pace of scientific research and innovation.
